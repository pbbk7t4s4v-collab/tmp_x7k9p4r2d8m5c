#!/usr/bin/env python3
"""
æœºå™¨å­¦ä¹ è¯¾ç¨‹è®²ä¹‰ Manim ä»£ç ç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
1. è¯»å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ *_*.md æ–‡ä»¶
2. ä½¿ç”¨ Page_Coder.txt ä½œä¸º prompt è°ƒç”¨å¤§æ¨¡å‹
3. ç”Ÿæˆå¯¹åº”çš„ Manim Python ä»£ç 
4. ä¿å­˜åˆ° Code/æ–‡ä»¶å¤¹å/ ç›®å½•ä¸‹

ä½œè€…ï¼šEduAgent ML Assistant
"""

import os
import re
import glob
import json
import argparse
import base64
from pathlib import Path
from typing import List, Tuple
import time
import concurrent.futures
import shutil

# å¤§æ¨¡å‹ API é…ç½®
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

class ManimCodeGenerator:
    def __init__(self, config_path: str = "config.json", verbose: bool = False):
        """
        åˆå§‹åŒ–ä»£ç ç”Ÿæˆå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.prompt_template = self._load_prompt_template("prompt_templates/Page_Coder.txt")
        self.prompt_template_no_pic = self._load_prompt_template("prompt_templates/Page_Coder_with_no_pic.txt")
        self.planner_prompt_template = self._load_prompt_template("prompt_templates/Page_Pic_Planner.txt")
        self.verbose = verbose
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        if HAS_OPENAI:
            openai.api_key = self.config["llm_key"]
            openai.base_url = self.config["llm_settings"]["base_url"]
        else:
            raise ImportError("OpenAI library not found. Please install: pip install openai")
    
    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_prompt_template(self, path: str) -> str:
        """åŠ è½½ prompt æ¨¡æ¿"""
        prompt_file = Path(path)
        if not prompt_file.exists():
            raise FileNotFoundError(f"Prompt template not found: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    
    def find_section_files(self, folder_path: str) -> List[Tuple[str, str]]:
        """
        æŸ¥æ‰¾æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ç¬¦åˆ æ•°å­—_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            List of (filename, filepath) tuples
        """
        folder = Path(folder_path)
        if not folder.exists():
            raise FileNotFoundError(f"Folder not found: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶ï¼Œç„¶åç­›é€‰ç¬¦åˆ æ•°å­—_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        all_files = glob.glob(os.path.join(folder_path, "*.md"))
        files = []
        
        # åªä¿ç•™ç¬¦åˆ å‰ç¼€_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        pattern = re.compile(r'^(.+)_(\d+)\.md$')
        for filepath in all_files:
            filename = os.path.basename(filepath)
            if pattern.match(filename):
                files.append(filepath)
        
        # æ’åºç¡®ä¿æŒ‰å‰ç¼€å’Œæ•°å­—é¡ºåºå¤„ç†
        def sort_key(filepath):
            filename = os.path.basename(filepath)
            match = pattern.match(filename)
            if match:
                prefix = match.group(1)
                num = int(match.group(2))
                return (prefix, num)
            return ("", 0)
        
        files.sort(key=sort_key)
        
        result = []
        for filepath in files:
            filename = os.path.basename(filepath)
            result.append((filename, filepath))
        
        print(f"Found {len(result)} section files (å‰ç¼€_æ•°å­—.md format) in {folder_path}")
        print("Files to be processed:")
        for i, (filename, _) in enumerate(result, 1):
            print(f"  {i:2d}. {filename}")
        return result
    
    def read_markdown_content(self, filepath: str) -> str:
        """è¯»å– Markdown æ–‡ä»¶å†…å®¹"""
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    
    def plan_images(self, markdown_content: str, output_base_dir: str, filename: str) -> dict:
        """
        è°ƒç”¨ Planner åˆ¤æ–­æ˜¯å¦éœ€è¦å›¾ç‰‡
        """
        full_prompt = f"{self.planner_prompt_template}\n\nä»¥ä¸‹æ˜¯è¯¾ç¨‹å†…å®¹ï¼š\n\n{markdown_content}"
        
        max_retries = 5
        for attempt in range(max_retries):
            try:
                client = openai.OpenAI(
                    api_key=self.config["llm_key"],
                    base_url=self.config["llm_settings"]["base_url"]
                )
                
                response = client.chat.completions.create(
                    model="gemini-3-pro-preview",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™å­¦å†…å®¹ç­–åˆ’ä¸“å®¶ã€‚"},
                        {"role": "user", "content": full_prompt}
                    ],
                    max_tokens=self.config["llm_settings"]["max_tokens"],
                    temperature=self.config["llm_settings"]["temperature"]
                )
                raw_content = response.choices[0].message.content.strip()
                
                if not raw_content:
                    print(f"  Planner response is empty. Retrying ({attempt + 1}/{max_retries})...")
                    time.sleep(1)
                    continue

                # ä¿å­˜åŸå§‹å“åº”æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯• JSON è§£æå¤±è´¥çš„é—®é¢˜
                try:
                    log_dir = Path(output_base_dir).parent / "logs"
                    log_dir.mkdir(parents=True, exist_ok=True)
                    log_path = log_dir / f"{Path(filename).stem}_planner_response.txt"
                    with open(log_path, 'w', encoding='utf-8') as f:
                        f.write(f"File: {filename}\n")
                        f.write(f"Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write("-" * 40 + "\n")
                        f.write(raw_content)
                except Exception as e:
                    print(f"Failed to write planner log: {e}")

                # è§£æ JSON
                plan_result = {"needs_image": False, "images": []} # é»˜è®¤ä¿åº•å€¼
                parse_success = False

                try:
                    # 1. å°è¯•æ¸…ç† Markdown ä»£ç å—æ ‡è®°
                    content_to_parse = raw_content
                    if "```json" in content_to_parse:
                        content_to_parse = content_to_parse.split("```json")[1].split("```")[0]
                    elif "```" in content_to_parse:
                        content_to_parse = content_to_parse.split("```")[1].split("```")[0]
                    
                    content_to_parse = content_to_parse.strip()
                    
                    # 2. å°è¯•ç›´æ¥è§£æ
                    plan_result = json.loads(content_to_parse)
                    parse_success = True
                except json.JSONDecodeError:
                    # 3. å¦‚æœå¤±è´¥ï¼Œå°è¯•ç”¨æ­£åˆ™æå–ç¬¬ä¸€ä¸ª { ... }
                    try:
                        match = re.search(r'\{.*\}', raw_content, re.DOTALL)
                        if match:
                            json_str = match.group(0)
                            plan_result = json.loads(json_str)
                            parse_success = True
                    except Exception:
                        pass
                
                if not parse_success:
                    print(f"Failed to parse planner JSON for {filename}. Raw content preview: {raw_content[:100]}...")
                    # ä½¿ç”¨é»˜è®¤å€¼ï¼Œä½†ç»§ç»­æ‰§è¡Œä¿å­˜é€»è¾‘
                
                # ä¿å­˜ Planner ç»“æœ (æ— è®ºæ˜¯è§£ææˆåŠŸçš„ï¼Œè¿˜æ˜¯ä¿åº•çš„)
                planner_dir = Path(output_base_dir).parent / "planner"
                planner_dir.mkdir(parents=True, exist_ok=True)
                
                output_filename = filename.replace('.md', '.json')
                output_filepath = planner_dir / output_filename
                
                with open(output_filepath, 'w', encoding='utf-8') as f:
                    json.dump(plan_result, f, indent=4, ensure_ascii=False)
                    
                if self.verbose:
                    if parse_success:
                        print(f"  Planner result saved to: {output_filepath}")
                    else:
                        print(f"  Planner parsing failed. Saved default JSON to: {output_filepath}")
                    
                return plan_result
                
            except Exception as e:
                print(f"Planner API call failed (Attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    # å³ä½¿ API è°ƒç”¨å¤±è´¥ï¼Œä¹Ÿå°è¯•ä¿å­˜ä¸€ä¸ªä¿åº• JSONï¼Œä»¥ä¾¿åç»­æµç¨‹çŸ¥é“è¿™é‡Œå‡ºé”™äº†ä½†æœ‰æ–‡ä»¶
                    try:
                        planner_dir = Path(output_base_dir).parent / "planner"
                        planner_dir.mkdir(parents=True, exist_ok=True)
                        output_filename = filename.replace('.md', '.json')
                        output_filepath = planner_dir / output_filename
                        with open(output_filepath, 'w', encoding='utf-8') as f:
                            json.dump({"needs_image": False, "images": []}, f, indent=4, ensure_ascii=False)
                    except Exception:
                        pass
                    return {"needs_image": False, "images": []}
        
        return {"needs_image": False, "images": []}

    def call_llm_api(self, markdown_content: str, prompt_template: str) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹ API ç”Ÿæˆ Manim ä»£ç 
        
        Args:
            markdown_content: Markdown æ ¼å¼çš„è¯¾ç¨‹å†…å®¹
            prompt_template: ä½¿ç”¨çš„ prompt æ¨¡æ¿
            
        Returns:
            ç”Ÿæˆçš„ Manim Python ä»£ç 
        """
        # æ„å»ºå®Œæ•´çš„ prompt
        full_prompt = f"{prompt_template}\n\nä»¥ä¸‹æ˜¯éœ€è¦è½¬æ¢ä¸º Manim åŠ¨ç”»çš„è¯¾ç¨‹å†…å®¹ï¼š\n\n{markdown_content}"
        
        max_retries = 5
        for attempt in range(max_retries):
            try:
                client = openai.OpenAI(
                    api_key=self.config["llm_key"],
                    base_url=self.config["llm_settings"]["base_url"]
                )
                
                response = client.chat.completions.create(
                    model="gemini-3-pro-preview",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Manim åŠ¨ç”»ä¸“å®¶ï¼Œä¸“é—¨ä¸ºè¯¾ç¨‹åˆ¶ä½œæ•™å­¦åŠ¨ç”»ã€‚"},
                        {"role": "user", "content": full_prompt}
                    ],
                    max_tokens=self.config["llm_settings"]["max_tokens"],
                    temperature=self.config["llm_settings"]["temperature"]
                )
                raw_content = response.choices[0].message.content.strip()
                
                if not raw_content:
                    print(f"  Coder response is empty. Retrying ({attempt + 1}/{max_retries})...")
                    time.sleep(1)
                    continue
                
                return self.clean_generated_code(raw_content)
                
            except Exception as e:
                print(f"API call failed (Attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return f"# Error generating code for this section\n# Error: {e}\npass"
        
        return f"# Error generating code for this section\n# Failed after {max_retries} attempts\npass"
    
    def generate_image(self, prompt: str, output_path: Path) -> bool:
        """
        è°ƒç”¨ gemini-3-pro-image-preview ç”Ÿæˆå›¾ç‰‡
        """
        max_retries = 5
        for attempt in range(max_retries):
            try:
                client = openai.OpenAI(
                    api_key=self.config["llm_key"],
                    base_url=self.config["llm_settings"]["base_url"]
                )
                
                # æ„é€ æç¤ºè¯
                full_prompt = f"Generate a high-quality image based on the following description: {prompt}. The aspect ratio of the image must be 1:1."
                
                if self.verbose:
                    print(f"    Generating image for: {prompt[:30]}... (Attempt {attempt + 1}/{max_retries})")
                
                response_stream = client.chat.completions.create(
                    model=self.config.get("picture_settings", {}).get("model", "gemini-3-pro-image-preview"),
                    messages=[
                        {"role": "user", "content": full_prompt}
                    ],
                    stream=True
                )

                full_content = ""
                for chunk in response_stream:
                    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                        full_content += chunk.choices[0].delta.content
                
                # è§£æ Markdown å›¾ç‰‡é“¾æ¥
                image_url = None
                start_index = full_content.find('![image](')
                if start_index != -1:
                    end_index = full_content.find(')', start_index)
                    if end_index != -1:
                        image_url = full_content[start_index + 9 : end_index]

                if not image_url:
                    print(f"    Failed to find image url in response.")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    else:
                        break

                if image_url.startswith("data:image"):
                    b64_str = image_url.split(",")[1]
                    img_bytes = base64.b64decode(b64_str)
                    
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(output_path, "wb") as f:
                        f.write(img_bytes)
                    return True
                else:
                    print(f"    Unsupported image URL format: {image_url[:30]}...")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    else:
                        break

            except Exception as e:
                print(f"    Image generation failed (Attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    break
        
        # Fallback mechanism
        print(f"    All {max_retries} attempts failed. Using placeholder.")
        try:
            # Try to find placeholder.png in the same directory as the script
            script_dir = Path(__file__).parent
            placeholder_path = script_dir / "placeholder.png"
            
            if not placeholder_path.exists():
                 # Try current working directory
                 placeholder_path = Path("placeholder.png")
            
            if placeholder_path.exists():
                output_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy(placeholder_path, output_path)
                print(f"    Copied placeholder to {output_path}")
                return True
            else:
                print(f"    Placeholder not found at {placeholder_path}")
                return False
        except Exception as e:
            print(f"    Failed to use fallback placeholder: {e}")
            return False

    def process_images_in_code(self, code: str, output_dir: str, filename: str) -> str:
        """
        å¤„ç†ä»£ç ä¸­çš„å›¾ç‰‡ç”Ÿæˆè¯·æ±‚
        """
        # åŒ¹é… ImageMobject("1.png") # æè¿°
        pattern = re.compile(r'ImageMobject\("([^"]+)"\)\s*#\s*(.*)')
        
        lines = code.split('\n')
        new_lines = []
        
        file_stem = Path(filename).stem # e.g. 1_1
        # parent(<output_dir>)/pictures/<n>_<m>
        pictures_dir = Path(output_dir).parent / "pictures" / file_stem
        
        for line in lines:
            match = pattern.search(line)
            if match:
                img_filename = match.group(1) # 1.png
                description = match.group(2).strip() # æè¿°
                
                img_path = pictures_dir / img_filename
                
                # ç”Ÿæˆå›¾ç‰‡
                if self.generate_image(description, img_path):
                    # æ›¿æ¢ä¸ºç»å¯¹è·¯å¾„
                    abs_path = str(img_path.absolute()).replace('\\', '/')
                    new_line = line.replace(f'"{img_filename}"', f'"{abs_path}"')
                    new_lines.append(new_line)
                else:
                    new_lines.append(line) # ç”Ÿæˆå¤±è´¥åˆ™ä¿ç•™åŸæ ·
            else:
                new_lines.append(line)
                
        return '\n'.join(new_lines)

    def clean_generated_code(self, raw_code: str) -> str:
        """
        æ¸…ç†ç”Ÿæˆçš„ä»£ç ï¼Œå»é™¤ Markdown ä»£ç å—æ ‡è®°ç¬¦å·
        
        Args:
            raw_code: åŸå§‹ç”Ÿæˆçš„ä»£ç ï¼ˆå¯èƒ½åŒ…å« ```python ç­‰æ ‡è®°ï¼‰
            
        Returns:
            æ¸…ç†åçš„çº¯ Python ä»£ç 
        """
        # å»é™¤å¼€å¤´çš„ä»£ç å—æ ‡è®°
        lines = raw_code.strip().split('\n')
        
        # æ£€æŸ¥å¹¶å»é™¤å¼€å¤´çš„ ```python æˆ– ```
        if lines and lines[0].strip().startswith('```'):
            lines = lines[1:]
        
        # æ£€æŸ¥å¹¶å»é™¤ç»“å°¾çš„ ```
        if lines and lines[-1].strip() == '```':
            lines = lines[:-1]
        
        # é‡æ–°ç»„åˆä»£ç 
        cleaned_code = '\n'.join(lines).strip()
        
        # ç¡®ä¿ä»£ç ä¸ä¸ºç©º
        if not cleaned_code:
            cleaned_code = "# Empty code generated\npass"
        
        return cleaned_code
    
    def save_python_code(self, code: str, output_filepath: str):
        """ä¿å­˜ç”Ÿæˆçš„ Python ä»£ç åˆ°æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_filepath)
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜ä»£ç 
        with open(output_filepath, 'w', encoding='utf-8') as f:
            f.write(code)
        
        print(f"Saved: {output_filepath}")
    
    def process_single_file(self, filename_filepath, output_base_dir, delay_seconds):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            filename_filepath: (filename, filepath) tuple
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            delay_seconds: å»¶è¿Ÿç§’æ•°
        """
        filename, filepath = filename_filepath
        try:
            # è¯»å–Markdownå†…å®¹
            markdown_content = self.read_markdown_content(filepath)
            if self.verbose:
                print(f"  Loaded {len(markdown_content)} characters from {filename}")
            
            # 1. è°ƒç”¨ Planner
            if self.verbose:
                print(f"  Calling Planner for {filename}...")
            plan_result = self.plan_images(markdown_content, output_base_dir, filename)
            needs_image = plan_result.get("needs_image", False)
            
            # 2. é€‰æ‹© Prompt æ¨¡æ¿å¹¶å‡†å¤‡å›¾ç‰‡å»ºè®®
            image_plan_str = ""
            if needs_image:
                selected_prompt = self.prompt_template
                if self.verbose:
                    print(f"  Planner decided: Images NEEDED. Using standard prompt.")
                
                # æ ¼å¼åŒ–å›¾ç‰‡å»ºè®®
                images = plan_result.get("images", [])
                if images:
                    image_plan_str = "\n\nã€Planner å›¾ç‰‡å»ºè®®ã€‘\nè¯·å‚è€ƒä½¿ç”¨ä»¥ä¸‹å›¾ç‰‡ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æè¿°ç”Ÿæˆä»£ç ï¼š\n"
                    for img in images:
                        idx = img.get("index")
                        desc = img.get("description")
                        image_plan_str += f"- å›¾ç‰‡ {idx} (ImageMobject(\"{idx}.png\")): {desc}\n"
            else:
                selected_prompt = self.prompt_template_no_pic
                if self.verbose:
                    print(f"  Planner decided: NO images needed. Using no-pic prompt.")

            # 3. è°ƒç”¨LLMç”Ÿæˆä»£ç 
            if self.verbose:
                print(f"  Calling LLM API for {filename}...")
            
            # å°†å›¾ç‰‡å»ºè®®é™„åŠ åˆ° markdown_content ä¹‹å‰ï¼Œä½œä¸ºä¸Šä¸‹æ–‡çš„ä¸€éƒ¨åˆ†
            content_with_plan = image_plan_str + "\n" + markdown_content
            
            manim_code = self.call_llm_api(content_with_plan, selected_prompt)
            
            # 4. å¤„ç†å›¾ç‰‡ç”Ÿæˆ (ä»…å½“ needs_image ä¸º True æ—¶)
            if needs_image:
                if self.verbose:
                    print(f"  Processing images for {filename}...")
                manim_code = self.process_images_in_code(manim_code, output_base_dir, filename)
            else:
                if self.verbose:
                    print(f"  Skipping image processing as per planner decision.")
            
            # ä¿å­˜Pythonä»£ç 
            output_filename = filename.replace('.md', '.py')
            output_filepath = os.path.join(output_base_dir, output_filename)
            self.save_python_code(manim_code, output_filepath)
            
            if self.verbose:
                print(f"  Saved: {output_filepath}")
            
            # å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
            time.sleep(delay_seconds)
            
            return f"Success: {filename}"
            
        except Exception as e:
            error_msg = f"Error processing {filename}: {e}"
            print(error_msg)
            return error_msg
    def process_folder(self, input_folder: str, output_dir: str, delay_seconds: float = 1.0, max_workers: int = 4):
        """
        å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨å¹¶è¡Œå¤„ç†æé«˜æ•ˆç‡
        
        Args:
            input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            delay_seconds: APIè°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰
        """
        start_time = time.time()  # å¼€å§‹è®¡æ—¶
        
        # è·å–æ–‡ä»¶å¤¹åç§°
        output_base_dir = output_dir
        
        print(f"Processing folder: {input_folder}")
        print(f"Output directory: {output_base_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰sectionæ–‡ä»¶
        section_files = self.find_section_files(input_folder)
        
        if not section_files:
            print("No section files found!")
            return
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ä»¶
        # max_workers = 4  # è®¾ç½®æœ€å¤§å¹¶å‘æ•°ï¼Œé¿å…APIé™åˆ¶
        print(f"Starting parallel processing with {max_workers} workers...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.process_single_file, filename_filepath, output_base_dir, delay_seconds): filename_filepath
                for filename_filepath in section_files
            }
            
            total_tasks = len(future_to_file)
            completed_tasks = 0
            print(f"ğŸ“¤ Submitted {total_tasks} tasks to thread pool (max {max_workers} concurrent workers)")
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_file):
                filename_filepath = future_to_file[future]
                try:
                    result = future.result()
                    if self.verbose:
                        print(result)
                except Exception as exc:
                    print(f'{filename_filepath[0]} generated an exception: {exc}')
                
                completed_tasks += 1
                remaining_tasks = total_tasks - completed_tasks
                active_workers = min(max_workers, remaining_tasks + (1 if remaining_tasks > 0 else 0))  # ä¼°ç®—æ´»è·ƒå·¥ä½œçº¿ç¨‹
                print(f"ğŸ”„ Progress: {completed_tasks}/{total_tasks} completed, {remaining_tasks} remaining, ~{active_workers} active workers")
        
        end_time = time.time()  # ç»“æŸè®¡æ—¶
        total_time = end_time - start_time
        
        print(f"\nâœ… Parallel processing completed! Output saved to: {output_base_dir}")
        print(f"â±ï¸  Total processing time: {total_time:.2f} seconds")
        print(f"ğŸ“Š Processed {len(section_files)} files in parallel with {max_workers} workers")
    
    def pipeline(self, input_folder: str, output_dir: str, delay_seconds: float = 1.0, max_workers: int = 4):
        """
        ç®€åŒ–çš„æµæ°´çº¿æ¥å£
        
        Args:
            input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            delay_seconds: APIè°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰
        """
        pipeline_start_time = time.time()
        result = self.process_folder(input_folder, output_dir, delay_seconds=delay_seconds, max_workers=max_workers)
        pipeline_end_time = time.time()
        pipeline_total_time = pipeline_end_time - pipeline_start_time
        print(f"ğŸ”„ Pipeline execution time: {pipeline_total_time:.2f} seconds")
        return result


def main():
    parser = argparse.ArgumentParser(description="Generate Manim codes from ML course sections")
    parser.add_argument("--folder", default="/home/TeachMaster/ML/nano_test/test_markdown", help="Input folder containing *_*.md files")
    parser.add_argument("--config", default="config.json", help="Config file path")
    parser.add_argument("--output_dir", default="/home/TeachMaster/ML/nano_test/12_13_2/output_code", help="Output directory for generated python files")
    parser.add_argument("--delay", type=float, default=1.0,
                        help="Delay between API calls in seconds")
    parser.add_argument("--workers", type=int, default=4,
                        help="Number of parallel workers to use")

    args = parser.parse_args()

    try:
        # åˆ›å»ºç”Ÿæˆå™¨å¹¶å¤„ç†æ–‡ä»¶å¤¹
        generator = ManimCodeGenerator(config_path=args.config)
        generator.pipeline(args.folder, output_dir=args.output_dir, delay_seconds=args.delay, max_workers=args.workers)

    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()