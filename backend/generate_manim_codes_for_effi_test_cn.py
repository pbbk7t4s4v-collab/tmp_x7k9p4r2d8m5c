#!/usr/bin/env python3
"""
æœºå™¨å­¦ä¹ è¯¾ç¨‹è®²ä¹‰ Manim ä»£ç ç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
1. è¯»å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ *_*.md æ–‡ä»¶
2. ä½¿ç”¨ Page_Coder.txt ä½œä¸º prompt è°ƒç”¨å¤§æ¨¡å‹
3. ç”Ÿæˆå¯¹åº”çš„ Manim Python ä»£ç 
4. ä¿å­˜åˆ° Code/æ–‡ä»¶å¤¹å/ ç›®å½•ä¸‹

ä½œè€…ï¼šEduAgent ML Assistant
"""

import os
import re
import glob
import json
import argparse
from pathlib import Path
from typing import List, Tuple
import time
import concurrent.futures

# å¤§æ¨¡å‹ API é…ç½®
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False


class ManimCodeGenerator_cn:
    def __init__(self, config_path: str = "config.json", verbose: bool = False):
        """
        åˆå§‹åŒ–ä»£ç ç”Ÿæˆå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.prompt_template = self._load_prompt_template()
        self.verbose = verbose
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        if HAS_OPENAI:
            openai.api_key = self.config["llm_key"]
            openai.base_url = self.config["llm_settings"]["base_url"]
        else:
            raise ImportError("OpenAI library not found. Please install: pip install openai")
    
    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_prompt_template(self) -> str:
        """åŠ è½½ Page_Coder.txt ä½œä¸º prompt æ¨¡æ¿"""
        prompt_file = Path("prompt_templates/Page_Coder_cn.txt")
        if not prompt_file.exists():
            raise FileNotFoundError(f"Prompt template not found: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    
    def find_section_files(self, folder_path: str) -> List[Tuple[str, str]]:
        """
        æŸ¥æ‰¾æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ç¬¦åˆ æ•°å­—_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            List of (filename, filepath) tuples
        """
        folder = Path(folder_path)
        if not folder.exists():
            raise FileNotFoundError(f"Folder not found: {folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶ï¼Œç„¶åç­›é€‰ç¬¦åˆ æ•°å­—_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        all_files = glob.glob(os.path.join(folder_path, "*.md"))
        files = []
        
        # åªä¿ç•™ç¬¦åˆ å‰ç¼€_æ•°å­—.md æ ¼å¼çš„æ–‡ä»¶
        pattern = re.compile(r'^(.+)_(\d+)\.md$')
        for filepath in all_files:
            filename = os.path.basename(filepath)
            if pattern.match(filename):
                files.append(filepath)
        
        # æ’åºç¡®ä¿æŒ‰å‰ç¼€å’Œæ•°å­—é¡ºåºå¤„ç†
        def sort_key(filepath):
            filename = os.path.basename(filepath)
            match = pattern.match(filename)
            if match:
                prefix = match.group(1)
                num = int(match.group(2))
                return (prefix, num)
            return ("", 0)
        
        files.sort(key=sort_key)
        
        result = []
        for filepath in files:
            filename = os.path.basename(filepath)
            result.append((filename, filepath))
        
        print(f"Found {len(result)} section files (å‰ç¼€_æ•°å­—.md format) in {folder_path}")
        print("Files to be processed:")
        for i, (filename, _) in enumerate(result, 1):
            print(f"  {i:2d}. {filename}")
        return result
    
    def read_markdown_content(self, filepath: str) -> str:
        """è¯»å– Markdown æ–‡ä»¶å†…å®¹"""
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    
    def call_llm_api(self, markdown_content: str) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹ API ç”Ÿæˆ Manim ä»£ç 
        
        Args:
            markdown_content: Markdown æ ¼å¼çš„è¯¾ç¨‹å†…å®¹
            
        Returns:
            ç”Ÿæˆçš„ Manim Python ä»£ç 
        """
        # æ„å»ºå®Œæ•´çš„ prompt
        full_prompt = f"{self.prompt_template}\n\nä»¥ä¸‹æ˜¯éœ€è¦è½¬æ¢ä¸º Manim åŠ¨ç”»çš„è¯¾ç¨‹å†…å®¹ï¼š\n\n{markdown_content}"
        
        try:
            client = openai.OpenAI(
                api_key=self.config["llm_key"],
                base_url=self.config["llm_settings"]["base_url"]
            )
            
            response = client.chat.completions.create(
                model="gemini-3-pro-preview",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Manim åŠ¨ç”»ä¸“å®¶ï¼Œä¸“é—¨ä¸ºè¯¾ç¨‹åˆ¶ä½œæ•™å­¦åŠ¨ç”»ã€‚"},
                    {"role": "user", "content": full_prompt}
                ],
                max_tokens=self.config["llm_settings"]["max_tokens"],
                temperature=self.config["llm_settings"]["temperature"]
            )
            raw_content = response.choices[0].message.content.strip()
            return self.clean_generated_code(raw_content)
            
        except Exception as e:
            print(f"API call failed: {e}")
            return f"# Error generating code for this section\n# Error: {e}\npass"
    
    def clean_generated_code(self, raw_code: str) -> str:
        """
        æ¸…ç†ç”Ÿæˆçš„ä»£ç ï¼Œå»é™¤ Markdown ä»£ç å—æ ‡è®°ç¬¦å·
        
        Args:
            raw_code: åŸå§‹ç”Ÿæˆçš„ä»£ç ï¼ˆå¯èƒ½åŒ…å« ```python ç­‰æ ‡è®°ï¼‰
            
        Returns:
            æ¸…ç†åçš„çº¯ Python ä»£ç 
        """
        # å»é™¤å¼€å¤´çš„ä»£ç å—æ ‡è®°
        lines = raw_code.strip().split('\n')
        
        # æ£€æŸ¥å¹¶å»é™¤å¼€å¤´çš„ ```python æˆ– ```
        if lines and lines[0].strip().startswith('```'):
            lines = lines[1:]
        
        # æ£€æŸ¥å¹¶å»é™¤ç»“å°¾çš„ ```
        if lines and lines[-1].strip() == '```':
            lines = lines[:-1]
        
        # é‡æ–°ç»„åˆä»£ç 
        cleaned_code = '\n'.join(lines).strip()
        
        # ç¡®ä¿ä»£ç ä¸ä¸ºç©º
        if not cleaned_code:
            cleaned_code = "# Empty code generated\npass"
        
        return cleaned_code
    
    def save_python_code(self, code: str, output_filepath: str):
        """ä¿å­˜ç”Ÿæˆçš„ Python ä»£ç åˆ°æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_filepath)
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜ä»£ç 
        with open(output_filepath, 'w', encoding='utf-8') as f:
            f.write(code)
        
        print(f"Saved: {output_filepath}")
    
    def process_single_file(self, filename_filepath, output_base_dir, delay_seconds):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            filename_filepath: (filename, filepath) tuple
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            delay_seconds: å»¶è¿Ÿç§’æ•°
        """
        filename, filepath = filename_filepath
        try:
            # è¯»å–Markdownå†…å®¹
            markdown_content = self.read_markdown_content(filepath)
            if self.verbose:
                print(f"  Loaded {len(markdown_content)} characters from {filename}")
            
            # è°ƒç”¨LLMç”Ÿæˆä»£ç 
            if self.verbose:
                print(f"  Calling LLM API for {filename}...")
            manim_code = self.call_llm_api(markdown_content)
            
            # ä¿å­˜Pythonä»£ç 
            output_filename = filename.replace('.md', '.py')
            output_filepath = os.path.join(output_base_dir, output_filename)
            self.save_python_code(manim_code, output_filepath)
            
            if self.verbose:
                print(f"  Saved: {output_filepath}")
            
            # å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
            time.sleep(delay_seconds)
            
            return f"Success: {filename}"
            
        except Exception as e:
            error_msg = f"Error processing {filename}: {e}"
            print(error_msg)
            return error_msg
    def process_folder(self, input_folder: str, output_dir: str, delay_seconds: float = 1.0, max_workers: int = 4):
        """
        å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨å¹¶è¡Œå¤„ç†æé«˜æ•ˆç‡
        
        Args:
            input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            delay_seconds: APIè°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰
        """
        start_time = time.time()  # å¼€å§‹è®¡æ—¶
        
        # è·å–æ–‡ä»¶å¤¹åç§°
        output_base_dir = output_dir
        
        print(f"Processing folder: {input_folder}")
        print(f"Output directory: {output_base_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰sectionæ–‡ä»¶
        section_files = self.find_section_files(input_folder)
        
        if not section_files:
            print("No section files found!")
            return
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ä»¶
        # max_workers = 4  # è®¾ç½®æœ€å¤§å¹¶å‘æ•°ï¼Œé¿å…APIé™åˆ¶
        print(f"Starting parallel processing with {max_workers} workers...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.process_single_file, filename_filepath, output_base_dir, delay_seconds): filename_filepath
                for filename_filepath in section_files
            }
            
            total_tasks = len(future_to_file)
            completed_tasks = 0
            print(f"ğŸ“¤ Submitted {total_tasks} tasks to thread pool (max {max_workers} concurrent workers)")
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_file):
                filename_filepath = future_to_file[future]
                try:
                    result = future.result()
                    if self.verbose:
                        print(result)
                except Exception as exc:
                    print(f'{filename_filepath[0]} generated an exception: {exc}')
                
                completed_tasks += 1
                remaining_tasks = total_tasks - completed_tasks
                active_workers = min(max_workers, remaining_tasks + (1 if remaining_tasks > 0 else 0))  # ä¼°ç®—æ´»è·ƒå·¥ä½œçº¿ç¨‹
                print(f"ğŸ”„ Progress: {completed_tasks}/{total_tasks} completed, {remaining_tasks} remaining, ~{active_workers} active workers")
        
        end_time = time.time()  # ç»“æŸè®¡æ—¶
        total_time = end_time - start_time
        
        print(f"\nâœ… Parallel processing completed! Output saved to: {output_base_dir}")
        print(f"â±ï¸  Total processing time: {total_time:.2f} seconds")
        print(f"ğŸ“Š Processed {len(section_files)} files in parallel with {max_workers} workers")
    
    def pipeline(self, input_folder: str, output_dir: str, delay_seconds: float = 1.0, max_workers: int = 4):
        """
        ç®€åŒ–çš„æµæ°´çº¿æ¥å£
        
        Args:
            input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            delay_seconds: APIè°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰
        """
        pipeline_start_time = time.time()
        result = self.process_folder(input_folder, output_dir, delay_seconds=delay_seconds, max_workers=max_workers)
        pipeline_end_time = time.time()
        pipeline_total_time = pipeline_end_time - pipeline_start_time
        print(f"ğŸ”„ Pipeline execution time: {pipeline_total_time:.2f} seconds")
        return result


def main():
    parser = argparse.ArgumentParser(description="Generate Manim codes from ML course sections")
    parser.add_argument("--folder", default="./effi_test/markdown", help="Input folder containing *_*.md files")
    parser.add_argument("--config", default="config.json", help="Config file path")
    parser.add_argument("--output_dir", default="./effi_test/output_code", help="Output directory for generated python files")
    parser.add_argument("--delay", type=float, default=1.0,
                        help="Delay between API calls in seconds")
    parser.add_argument("--workers", type=int, default=4,
                        help="Number of parallel workers to use")

    args = parser.parse_args()

    try:
        # åˆ›å»ºç”Ÿæˆå™¨å¹¶å¤„ç†æ–‡ä»¶å¤¹
        generator = ManimCodeGenerator(config_path=args.config)
        generator.pipeline(args.folder, output_dir=args.output_dir, delay_seconds=args.delay, max_workers=args.workers)

    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    main()